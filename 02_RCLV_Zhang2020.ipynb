{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The goal of this notebook is to reproduce Section 2 in Zhang et al. (2020)\n",
    "\n",
    "This notebook attempts to reproduce the results from [Zhang et al. 2020](https://www.mdpi.com/2311-5521/5/1/2) using a two-layer QG model. Once the flow is seeded with Lagragian particles, we use the Lagrangian Averaged Vorticity Deviation (LAVD) method to identify coherent eddies.  \n",
    "\n",
    "`pyqg` is used to spinup a two-layer QG turbulence system. We will use the same nondimensional bottom friction and beta parameters to simulate the dynamics of the Southern Ocean. \n",
    "\n",
    "`floater` will be helpful to implement the LAVD technique to detect coherent eddies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import pi\n",
    "import argparse\n",
    "import pyqg\n",
    "from pyqg import diagnostic_tools as tools\n",
    "from pyqg import qg_model, particles\n",
    "from floater import rclv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the model and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = 3600*24\n",
    "year = 360*day\n",
    "dt = day/72/2  # time step  \n",
    "\n",
    "L = 1200e3   # domain size\n",
    "Ld = 15e3  # Rossby deformation radius\n",
    "nx = 256*2  # number of grid points in x direction\n",
    "\n",
    "delta = 0.25\n",
    "H1 = 4000*(delta/(1+delta)) #upper layer thickness [m]\n",
    "\n",
    "U1 = 0.04  # layer 1 zonal velocity [m/s]\n",
    "U2 = 0.0   # layer 2 zonal velocity [m/s]\n",
    "\n",
    "rekday = 20\n",
    "rek =  1/(rekday*day)   # linear bottom drag coeff. [s^-1] \n",
    "f0 = -1.2e-4    # Coriolis param. [s^-1]\n",
    "beta = 1.3e-11  # planatery vorticity gradient [m^-1 s^-1]\n",
    "\n",
    "Ti = Ld/abs(U1)\n",
    "tmax = 10*year # tmax is like seconds in 10 years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pyqg.QGModel(nx=nx, L=L,dt=dt, tmax=tmax, twrite=50000, tavestart=10*year, \n",
    "               ntd=6, beta=beta, rd=Ld, delta=delta, H1=H1, U1=U1, U2=U2, rek=rek) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set upper and lower layer PV anomalies (in spatial coordinates):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = 1.e-6\n",
    "qi = sig*np.vstack([np.random.randn(m.nx,m.ny)[np.newaxis,],\n",
    "                  np.random.randn(m.nx,m.ny)[np.newaxis,]])\n",
    "m.set_q(qi) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let model run. *This takes several hours*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "m.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot upper and lower PV anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_upper1=m.q[0]\n",
    "q_upper2=m.q[1]\n",
    "\n",
    "plt.figure(figsize=(18,4))\n",
    "plt.rc('xtick', labelsize=20); plt.rc('ytick', labelsize=20)\n",
    "plt.subplot(121)\n",
    "plt.contourf(m.x, m.y, q_upper1, 24, cmap='RdBu_r')\n",
    "plt.xlabel('x'); plt.ylabel('y'); plt.title('Upper Level PV')\n",
    "plt.colorbar()\n",
    "plt.subplot(122)\n",
    "plt.contourf(m.x, m.y, q_upper2, 24, cmap='RdBu_r')\n",
    "plt.xlabel('x'); plt.ylabel('y'); plt.title('Lower Level PV')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Lagrangian particles and advect using gridded u and v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = m.dx/2   # or 4\n",
    "dy = m.dy/2\n",
    "\n",
    "x0,y0 = np.meshgrid(np.arange(0,m.L,dx)+dx/2,\n",
    "                    np.arange(0,m.W,dy)+dy/2)\n",
    "pNy, pNx = x0.shape\n",
    "\n",
    "x0 = x0.ravel()\n",
    "y0 = y0.ravel()\n",
    "\n",
    "Npart = x0.size\n",
    "Ndays = 90 # times to integrate\n",
    "Tpart = day*Ndays # length of particle trajectory\n",
    "Tsave =  day  # daily data is saved\n",
    "Nhold = Ndays # number of days to save\n",
    "m.tmax = m.t + Tpart # let the model run some more by adding time to tmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "Tstart = m.t/day\n",
    "n = -1\n",
    "\n",
    "particle_history = np.zeros((Nhold, 3, Npart))\n",
    "q = np.zeros([Nhold, 2, m.ny ,m.nx])\n",
    "ue = np.zeros([Nhold, m.ny, m.nx])\n",
    "ve = np.zeros([Nhold, m.ny, m.nx])\n",
    "pe = np.zeros([Nhold, m.ny, m.nx])\n",
    "\n",
    "lpa = particles.GriddedLagrangianParticleArray2D(x0, y0, m.nx, m.ny,\n",
    "        periodic_in_x=True, periodic_in_y=True,\n",
    "        xmin=0, xmax=m.L, ymin=0, ymax=m.W)\n",
    "\n",
    "# set up extended grid for lagrangian particles\n",
    "x = np.hstack([m.x[0,0]-m.dx, m.x[0,:], m.x[0,-1]+m.dx])\n",
    "y = np.hstack([m.y[0,0]-m.dy, m.y[:,0], m.y[-1,0]+m.dy])\n",
    "\n",
    "uprev = m.ufull[0].copy()   \n",
    "vprev = m.vfull[0].copy()\n",
    "for snapshot in m.run_with_snapshots(tsnapstart=m.t, tsnapint=m.dt): \n",
    "\n",
    "    # set up velocities for Lagrangian advection\n",
    "    u = m.ufull[0]\n",
    "    v = m.vfull[0]\n",
    "    \n",
    "    lpa.step_forward_with_gridded_uv(uprev, vprev, u, v, m.dt)\n",
    "\n",
    "    uprev = u.copy()\n",
    "    vprev = v.copy()\n",
    "\n",
    "    if n==-1:\n",
    "        qi = m.q[0].copy()\n",
    "        ui = u.copy()\n",
    "        vi = v.copy()\n",
    "        \n",
    "        n+=1\n",
    "        \n",
    "    if (m.t % Tsave)==0:\n",
    "        if (m.t*(Tsave*10))==0:\n",
    "            print(m.t, n)\n",
    "\n",
    "        # calculate relative vorticity using PV anomaly\n",
    "        p = m.ifft(m.ph)\n",
    "        vort = m.q[0] - m.F1*(p[1]-p[0])\n",
    "        \n",
    "        # vorticty on particles\n",
    "        pvort = lpa.interpolate_gridded_scalar(lpa.x, lpa.y, vort)\n",
    "\n",
    "        particle_history = np.roll(particle_history, 1, axis=0)\n",
    "        particle_history[0,0] = lpa.x\n",
    "        particle_history[0,1] = lpa.y\n",
    "        particle_history[0,2] = pvort\n",
    "        # time goes backwards in particle history\n",
    "        \n",
    "        q = np.roll(q, 1, axis=0)\n",
    "        q[0] = m.q\n",
    "        ue = np.roll(ue, 1, axis=0)\n",
    "        ue[0] = m.u[0]\n",
    "        ve = np.roll(ve, 1, axis=0)\n",
    "        ve[0] = m.v[0]\n",
    "        pe = np.roll(pe, 1, axis=0)\n",
    "        pe[0] = p[0]\n",
    "\n",
    "        n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('/data/p1.2km_Trajectories_90days_m2.4km_rek%sdays_startday%s'%(rekday,Tstart),  \n",
    "  Tsave=Tsave, dx=dx, dy=dy, particle_history=particle_history, q=q, ue=ue, ve=ve, pe=pe,\n",
    "         pNx=pNx, pNy=pNy, Nhold=Nhold)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('/data/p1.2km_Trajectories_90days_m2.4km_rek20days_startday3600.0.npz',allow_pickle=True) as data:\n",
    "    Tsave = data['Tsave']\n",
    "    dx = data['dx']\n",
    "    dy = data['dy']\n",
    "    particle_history = data['particle_history']\n",
    "    q = data['q']\n",
    "    ue = data['ue']\n",
    "    ve = data['ve']\n",
    "    pe = data['pe']\n",
    "    pNx = data['pNx']\n",
    "    pNy = data['pNy']\n",
    "    Nhold = data['Nhold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RCLV identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_xy(Xseg,Yseg,L): \n",
    "    '''plot trajectories over periodic boundaries'''\n",
    "    plt.plot(Xseg,Yseg,'k',linewidth=3) #,'k',linewidth=3\n",
    "    plt.plot(Xseg-L,Yseg,'k',linewidth=3)\n",
    "    plt.plot(Xseg+L,Yseg,'k',linewidth=3)\n",
    "    plt.plot(Xseg,Yseg-L,'k',linewidth=3)\n",
    "    plt.plot(Xseg,Yseg+L,'k',linewidth=3)\n",
    "    plt.xlim([0,L])\n",
    "    plt.ylim([0,L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Eddy detection\n",
    "\n",
    "# Tstart = 12510.\n",
    "# datafile = np.load('p1.2km_Trajectories_90days_m2.4km_rek%sdays_startday%s.npz'\n",
    "#                    %(rekday,Tstart),allow_pickle=True)\n",
    "# Ndays = 90\n",
    "# particle_history = datafile['particle_history'] \n",
    "# q = datafile['q']\n",
    "# Nhold= particle_history.shape[0]\n",
    "\n",
    "lav_abs = np.abs(particle_history[:,2].copy())  # absolute value of vorticity on particles\n",
    "lx,ly = particle_history[:,0].copy(),particle_history[:,1].copy() # particle trjectories\n",
    "\n",
    "# lq = np.zeros([Nhold,Npart])\n",
    "# for i in range(Nhold):\n",
    "#     lq[i] = lpa.interpolate_gridded_scalar(lx[i], ly[i], q[i,0]) # get the PV on particles (if needed)\n",
    "    \n",
    "lx.shape = (Nhold, pNy, pNx)\n",
    "ly.shape = (Nhold, pNy, pNx)\n",
    "lav_abs.shape = (Nhold, pNy, pNx)\n",
    "# lq.shape = (Nhold, pNy, pNx)\n",
    "\n",
    "lx1 = np.unwrap(lx[::-1]*2*pi/m.W, axis=0)*m.W/(2*pi)  # unwrap trajectories to correct the jump of displacement at the periodic boundaries\n",
    "ly1 = np.unwrap(ly[::-1]*2*pi/m.L, axis=0)*m.L/(2*pi)\n",
    "lx1 = lx1[::-1]  # switch back to backward timing\n",
    "ly1 = ly1[::-1]\n",
    "\n",
    "ndays1 = 60  # lifetime of RCLV\n",
    "lavd1 = lav_abs[-ndays1:].mean(axis=0)  #LAVD field \n",
    "del(lav_abs)\n",
    "\n",
    "cov1 = 10.0  # convexity deficincy threshold, here uses 10.0 to disable it\n",
    "CI = -0.75   # threshold for coherency index\n",
    "min_area = 200  # minimum area (number of pixels) of RCLV\n",
    "\n",
    "kwargs = dict(min_distance=20,  # minimum distance between LAVD maxima (pixel units)\n",
    "              max_width=100,    # maximum width of the search window (pixel units)\n",
    "              CI_th=CI, CI_tol=0.01, convex_def=cov1, convex_def_tol=0.001, \n",
    "              init_contour_step_frac=0.64,  # the value with which to increment the initial contour level\n",
    "              min_limit_diff=1e-10, min_area=min_area, periodic=(True, True))\n",
    "\n",
    "contours1 = list(rclv.find_convex_contours(lavd1, \n",
    "                                           lx1[-1:-ndays1-1:-1], ly1[-1:-ndays1-1:-1], \n",
    "                                           dx=dx, dy=dy, # particle spacing, must have the same unit as lx1 and ly1\n",
    "                                           **kwargs))\n",
    "\n",
    "mask = rclv.label_points_in_contours(lavd1.shape, [c[1] for c in contours1])  #label particles in RCLVs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap = 0\n",
    "fig = plt.figure(120+snap, figsize=(14,14))\n",
    "plt.title('%s-day RCLVs: Bisection searching with CI>%s and cd<%s'%(ndays1,CI,cov1))  \n",
    "plt.imshow(q[-1,0]*1e5, origin='lower', extent=((0,m.L/1000,0,m.W/1000)), cmap='RdBu_r') # plot the PV field at inital time\n",
    "plt.xlabel('x(km)')\n",
    "plt.ylabel('y(km)')\n",
    "clt = plt.colorbar()\n",
    "clt.set_label('PV($10^{-5}s^{-1}$)')\n",
    "\n",
    "for n,contour in enumerate(contours1):\n",
    "    if (mask==n+1).sum()==0:  # sometimes an eddy may not be masked\n",
    "        continue\n",
    "\n",
    "    xc = np.mean(lx1[:,mask==n+1], axis=-1)  # the center of particle cloud in the n-th RCLV\n",
    "    yc = np.mean(ly1[:,mask==n+1], axis=-1)\n",
    "\n",
    "    plt.figure(120+snap)\n",
    "    plot_xy(xc[-1:-ndays1:-1]/1e3,yc[-1:-ndays1:-1]/1e3,m.L/1e3)  # trajectory of the center of particle cloud\n",
    "    plt.plot(lx[-ndays1,mask==n+1]/1e3,ly[-ndays1,mask==n+1]/1e3,'.')  # particle postions at the last time\n",
    "    plt.plot(contour[1][:,1]*dx/1e3,contour[1][:,0]*dx/1e3,'r',linewidth=3)  # boundary of RCLV at the initial time\n",
    "    plt.plot(contour[0][1]*dx/1e3,contour[0][0]*dx/1e3,'yo')  # center of particle cloud at the initial time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyqg_run",
   "language": "python",
   "name": "pyqg_run"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
