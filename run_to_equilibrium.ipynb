{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run QG model to equilibrium and plot KE & PV\n",
    "\n",
    "The model configuration will be identical to Zhang et al. (2020). We will use `run_with_snapshots` and `get_diagnostic` to save the PV anomaly and mean eddy kinetic energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pyqg\n",
    "from pyqg import diagnostic_tools as tools\n",
    "from pyqg import qg_model, particles\n",
    "import matplotlib.pyplot as plt\n",
    "from xarray_output import model_to_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the model and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = 3600*24 # seconds in day\n",
    "year = 365*day # seconds in year\n",
    "dt = day #/72/2  # time step  \n",
    "\n",
    "L = 1200e3  # domain size\n",
    "Ld = 15e3  # Rossby deformation radius\n",
    "nx = 256*2  # number of grid points in x direction\n",
    "\n",
    "delta = 0.25\n",
    "H1 = 4000*(delta/(1+delta)) #upper layer thickness [m]\n",
    "\n",
    "U1 = 0.04  # layer 1 zonal velocity [m/s]\n",
    "U2 = 0.0   # layer 2 zonal velocity [m/s]\n",
    "\n",
    "rekday = 20\n",
    "rek =  1/(rekday*day)   # linear bottom drag coeff. [s^-1] \n",
    "f0 = -1.2e-4    # Coriolis param. [s^-1]\n",
    "beta = 1.3e-11  # planatery vorticity gradient [m^-1 s^-1]\n",
    "\n",
    "Ti = Ld/abs(U1)\n",
    "tmax = 10*year # tmax is like seconds in 10 years\n",
    "\n",
    "# twrite: Interval for cfl writeout (units: number of timesteps)\n",
    "# tavestart: Start time for averaging (units: model time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:  Logger initialized\n"
     ]
    }
   ],
   "source": [
    "m = pyqg.QGModel(nx=nx, L=L, dt=dt, tmax=tmax, twrite=10000, tavestart=5*year, \n",
    "               ntd=6, beta=beta, rd=Ld, delta=delta, H1=H1, U1=U1, U2=U2, rek=rek) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set upper and lower layer PV anomalies (in spatial coordinates):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = 1.e-6\n",
    "qi = sig*np.vstack([np.random.randn(m.nx,m.ny)[np.newaxis,],\n",
    "                  np.random.randn(m.nx,m.ny)[np.newaxis,]])\n",
    "m.set_q(qi) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run model with snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-ab02730a497b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                        \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'z'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                        coords={'z': [1,2], 'time': [m.t],'x': m.x[0,:] ,'y': m.y[:,0]})\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mq_snaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq_snaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_int\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/lcs-ml/lib/python3.8/site-packages/xarray/core/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;34m\"objects, got %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         )\n\u001b[0;32m--> 239\u001b[0;31m     return f(\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombine_attrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/lcs-ml/lib/python3.8/site-packages/xarray/core/concat.py\u001b[0m in \u001b[0;36m_dataarray_concat\u001b[0;34m(arrays, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_temp_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m     ds = _dataset_concat(\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/lcs-ml/lib/python3.8/site-packages/xarray/core/concat.py\u001b[0m in \u001b[0;36m_dataset_concat\u001b[0;34m(datasets, dim, data_vars, coords, compat, positions, fill_value, join, combine_attrs)\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%r is not present in all datasets.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mresult_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/lcs-ml/lib/python3.8/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(variables, dim, positions, shortcut)\u001b[0m\n\u001b[1;32m   2811\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndexVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortcut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2812\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2813\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortcut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/lcs-ml/lib/python3.8/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(cls, variables, dim, positions, shortcut)\u001b[0m\n\u001b[1;32m   1813\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_axis_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m             \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1815\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mduck_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1816\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpositions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m                 \u001b[0;31m# TODO: deprecate this option -- we don't need it for groupby\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/lcs-ml/lib/python3.8/site-packages/xarray/core/duck_array_ops.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(arrays, axis)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;34m\"\"\"concatenate() with better dtype promotion rules.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mas_shared_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/lcs-ml/lib/python3.8/site-packages/xarray/core/duck_array_ops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meager_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "q_snaps = xr.DataArray(data=m.q[:, np.newaxis,:,:],\n",
    "                       dims=['z','time','x','y'],\n",
    "                       coords={'z': [1,2], 'time': [m.t],'x': m.x[0,:] ,'y': m.y[:,0]})\n",
    "\n",
    "for snapshot in m.run_with_snapshots(tsnapstart=m.t, tsnapint=m.dt): \n",
    "    q_int = xr.DataArray(data=m.q[:, np.newaxis,:,:],\n",
    "                       dims=['z','time','x','y'],\n",
    "                       coords={'z': [1,2], 'time': [m.t],'x': m.x[0,:] ,'y': m.y[:,0]})\n",
    "    q_snaps = xr.concat([q_snaps, q_int], \"time\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_snaps[0,0,:,:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               | DESCRIPTION\n",
      "--------------------------------------------------------------------------------\n",
      "APEflux    | spectral flux of available potential energy           \n",
      "APEgen     | total APE generation                                  \n",
      "APEgenspec | spectrum of APE generation                            \n",
      "EKE        | mean eddy kinetic energy                              \n",
      "EKEdiss    | total energy dissipation by bottom drag               \n",
      "Ensspec    | enstrophy spectrum                                    \n",
      "KEflux     | spectral flux of kinetic energy                       \n",
      "KEspec     |  kinetic energy spectrum                              \n",
      "entspec    | barotropic enstrophy spectrum                         \n",
      "q          | QGPV                                                  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-0275c7dd1963>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe_diagnostics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkespec_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_diagnostic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'KEspec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/projects/pyqg/pyqg/model.py\u001b[0m in \u001b[0;36mget_diagnostic\u001b[0;34m(self, dname)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_diagnostic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         return (self.diagnostics[dname]['value'] /\n\u001b[0m\u001b[1;32m    655\u001b[0m                 self.diagnostics[dname]['count'])\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'value'"
     ]
    }
   ],
   "source": [
    "m.describe_diagnostics()\n",
    "eke = m.get_diagnostic('EKE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "m.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot upper and lower PV anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_upper1=m.q[0]\n",
    "q_upper2=m.q[1]\n",
    "\n",
    "plt.figure(figsize=(18,4))\n",
    "plt.rc('xtick', labelsize=20); plt.rc('ytick', labelsize=20)\n",
    "plt.subplot(121)\n",
    "plt.contourf(m.x, m.y, q_upper1, 24, cmap='RdBu_r')\n",
    "plt.xlabel('x'); plt.ylabel('y'); plt.title('Upper Level PV')\n",
    "plt.colorbar()\n",
    "plt.subplot(122)\n",
    "plt.contourf(m.x, m.y, q_upper2, 24, cmap='RdBu_r')\n",
    "plt.xlabel('x'); plt.ylabel('y'); plt.title('Lower Level PV')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Lagrangian particles and advect using gridded u and v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = m.dx/2   # or 4\n",
    "dy = m.dy/2\n",
    "\n",
    "x0,y0 = np.meshgrid(np.arange(0,m.L,dx)+dx/2,\n",
    "                    np.arange(0,m.W,dy)+dy/2)\n",
    "pNy, pNx = x0.shape\n",
    "\n",
    "x0 = x0.ravel()\n",
    "y0 = y0.ravel()\n",
    "\n",
    "Npart = x0.size\n",
    "Ndays = 90 # times to integrate\n",
    "Tpart = day*Ndays # length of particle trajectory\n",
    "Tsave =  day  # daily data is saved\n",
    "Nhold = Ndays # number of days to save\n",
    "m.tmax = m.t + Tpart # let the model run some more by adding time to tmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "Tstart = m.t/day\n",
    "n = -1\n",
    "\n",
    "particle_history = np.zeros((Nhold, 3, Npart))\n",
    "q = np.zeros([Nhold, 2, m.ny ,m.nx])\n",
    "ue = np.zeros([Nhold, m.ny, m.nx])\n",
    "ve = np.zeros([Nhold, m.ny, m.nx])\n",
    "pe = np.zeros([Nhold, m.ny, m.nx])\n",
    "\n",
    "lpa = particles.GriddedLagrangianParticleArray2D(x0, y0, m.nx, m.ny,\n",
    "        periodic_in_x=True, periodic_in_y=True,\n",
    "        xmin=0, xmax=m.L, ymin=0, ymax=m.W)\n",
    "\n",
    "# set up extended grid for lagrangian particles\n",
    "x = np.hstack([m.x[0,0]-m.dx, m.x[0,:], m.x[0,-1]+m.dx])\n",
    "y = np.hstack([m.y[0,0]-m.dy, m.y[:,0], m.y[-1,0]+m.dy])\n",
    "\n",
    "uprev = m.ufull[0].copy()   \n",
    "vprev = m.vfull[0].copy()\n",
    "for snapshot in m.run_with_snapshots(tsnapstart=m.t, tsnapint=m.dt): \n",
    "\n",
    "    # set up velocities for Lagrangian advection\n",
    "    u = m.ufull[0]\n",
    "    v = m.vfull[0]\n",
    "    \n",
    "    lpa.step_forward_with_gridded_uv(uprev, vprev, u, v, m.dt)\n",
    "\n",
    "    uprev = u.copy()\n",
    "    vprev = v.copy()\n",
    "\n",
    "    if n==-1:\n",
    "        qi = m.q[0].copy()\n",
    "        ui = u.copy()\n",
    "        vi = v.copy()\n",
    "        \n",
    "        n+=1\n",
    "        \n",
    "    if (m.t % Tsave)==0:\n",
    "        if (m.t*(Tsave*10))==0:\n",
    "            print(m.t, n)\n",
    "\n",
    "        # calculate relative vorticity using PV anomaly\n",
    "        p = m.ifft(m.ph)\n",
    "        vort = m.q[0] - m.F1*(p[1]-p[0])\n",
    "        \n",
    "        # vorticty on particles\n",
    "        pvort = lpa.interpolate_gridded_scalar(lpa.x, lpa.y, vort)\n",
    "\n",
    "        particle_history = np.roll(particle_history, 1, axis=0)\n",
    "        particle_history[0,0] = lpa.x\n",
    "        particle_history[0,1] = lpa.y\n",
    "        particle_history[0,2] = pvort\n",
    "        # time goes backwards in particle history\n",
    "        \n",
    "        q = np.roll(q, 1, axis=0)\n",
    "        q[0] = m.q\n",
    "        ue = np.roll(ue, 1, axis=0)\n",
    "        ue[0] = m.u[0]\n",
    "        ve = np.roll(ve, 1, axis=0)\n",
    "        ve[0] = m.v[0]\n",
    "        pe = np.roll(pe, 1, axis=0)\n",
    "        pe[0] = p[0]\n",
    "\n",
    "        n+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RCLV identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_xy(Xseg,Yseg,L): \n",
    "    '''plot trajectories over periodic boundaries'''\n",
    "    plt.plot(Xseg,Yseg,'k',linewidth=3) #,'k',linewidth=3\n",
    "    plt.plot(Xseg-L,Yseg,'k',linewidth=3)\n",
    "    plt.plot(Xseg+L,Yseg,'k',linewidth=3)\n",
    "    plt.plot(Xseg,Yseg-L,'k',linewidth=3)\n",
    "    plt.plot(Xseg,Yseg+L,'k',linewidth=3)\n",
    "    plt.xlim([0,L])\n",
    "    plt.ylim([0,L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Eddy detection\n",
    "\n",
    "lav_abs = np.abs(particle_history[:,2].copy())  # absolute value of vorticity on particles\n",
    "lx,ly = particle_history[:,0].copy(),particle_history[:,1].copy() # particle trjectories\n",
    "\n",
    "# lq = np.zeros([Nhold,Npart])\n",
    "# for i in range(Nhold):\n",
    "#     lq[i] = lpa.interpolate_gridded_scalar(lx[i], ly[i], q[i,0]) # get the PV on particles (if needed)\n",
    "    \n",
    "lx.shape = (Nhold, pNy, pNx)\n",
    "ly.shape = (Nhold, pNy, pNx)\n",
    "lav_abs.shape = (Nhold, pNy, pNx)\n",
    "# lq.shape = (Nhold, pNy, pNx)\n",
    "\n",
    "lx1 = np.unwrap(lx[::-1]*2*pi/m.W, axis=0)*m.W/(2*pi)  # unwrap trajectories to correct the jump of displacement at the periodic boundaries\n",
    "ly1 = np.unwrap(ly[::-1]*2*pi/m.L, axis=0)*m.L/(2*pi)\n",
    "lx1 = lx1[::-1]  # switch back to backward timing\n",
    "ly1 = ly1[::-1]\n",
    "\n",
    "ndays1 = 60  # lifetime of RCLV\n",
    "lavd1 = lav_abs[-ndays1:].mean(axis=0)  #LAVD field \n",
    "del(lav_abs)\n",
    "\n",
    "cov1 = 10.0  # convexity deficincy threshold, here uses 10.0 to disable it\n",
    "CI = -0.75   # threshold for coherency index\n",
    "min_area = 200  # minimum area (number of pixels) of RCLV\n",
    "\n",
    "kwargs = dict(min_distance=20,  # minimum distance between LAVD maxima (pixel units)\n",
    "              max_width=100,    # maximum width of the search window (pixel units)\n",
    "              CI_th=CI, CI_tol=0.01, convex_def=cov1, convex_def_tol=0.001, \n",
    "              init_contour_step_frac=0.64,  # the value with which to increment the initial contour level\n",
    "              min_limit_diff=1e-10, min_area=min_area, periodic=(True, True))\n",
    "\n",
    "contours1 = list(rclv.find_convex_contours(lavd1, \n",
    "                                           lx1[-1:-ndays1-1:-1], ly1[-1:-ndays1-1:-1], \n",
    "                                           dx=dx, dy=dy, # particle spacing, must have the same unit as lx1 and ly1\n",
    "                                           **kwargs))\n",
    "\n",
    "mask = rclv.label_points_in_contours(lavd1.shape, [c[1] for c in contours1])  #label particles in RCLVs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap = 0\n",
    "fig = plt.figure(120+snap, figsize=(14,14))\n",
    "plt.title('%s-day RCLVs: Bisection searching with CI>%s and cd<%s'%(ndays1,CI,cov1))  \n",
    "plt.imshow(q[-1,0]*1e5, origin='lower', extent=((0,m.L/1000,0,m.W/1000)), cmap='RdBu_r') # plot the PV field at inital time\n",
    "plt.xlabel('x(km)')\n",
    "plt.ylabel('y(km)')\n",
    "clt = plt.colorbar()\n",
    "clt.set_label('PV($10^{-5}s^{-1}$)')\n",
    "\n",
    "for n,contour in enumerate(contours1):\n",
    "    if (mask==n+1).sum()==0:  # sometimes an eddy may not be masked\n",
    "        continue\n",
    "\n",
    "    xc = np.mean(lx1[:,mask==n+1], axis=-1)  # the center of particle cloud in the n-th RCLV\n",
    "    yc = np.mean(ly1[:,mask==n+1], axis=-1)\n",
    "\n",
    "    plt.figure(120+snap)\n",
    "    plot_xy(xc[-1:-ndays1:-1]/1e3,yc[-1:-ndays1:-1]/1e3,m.L/1e3)  # trajectory of the center of particle cloud\n",
    "    plt.plot(lx[-ndays1,mask==n+1]/1e3,ly[-ndays1,mask==n+1]/1e3,'.')  # particle postions at the last time\n",
    "    plt.plot(contour[1][:,1]*dx/1e3,contour[1][:,0]*dx/1e3,'r',linewidth=3)  # boundary of RCLV at the initial time\n",
    "    plt.plot(contour[0][1]*dx/1e3,contour[0][0]*dx/1e3,'yo')  # center of particle cloud at the initial time\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcs-ml",
   "language": "python",
   "name": "lcs-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
